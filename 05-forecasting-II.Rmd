```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(xts)
library(timetk)
library(forecast)

library(dplyr)
library(tsibble)
students <- read.csv('./students.csv', skip = 16, header = TRUE, na = '-', strip.white = TRUE, stringsAsFactors = TRUE)
students[, 3:18] <- apply(students[, 3:18], 2, function(y) as.numeric(gsub(",", "", y)))
students.total.xts <- students %>% filter(지역규모 == '계') %>% select(-지역규모)
students.total.xts <- as.xts(students.total.xts, order.by = as.Date(paste0(students.total.xts[,1], '-01-01'), format = '%Y-%m-%d'))
library(timetk)
students.total.ts <- students %>% 
  filter(지역규모 == '계') %>% 
  select(3:18) %>%
  ts(start = c(1999), frequency = 1)
students.tsibble <- as_tsibble(students, key = 지역규모, index = 연도)

employees <- read.csv('./산업별_취업자_20210206234505.csv', header = TRUE, na = '-', strip.white = TRUE, stringsAsFactors = TRUE)
colnames(employees) <- c('time', 'total', 'employees.edu')
employees$time <- as.Date(paste0(employees$time, '. 01'), format = '%Y. %m. %d')
employees.ts <- ts(employees, start = c(2013, 01), frequency = 12)
employees.xts <- xts(employees[,2:3], order.by = employees[,1])
employees$yearmonth <- yearmonth(employees$time)
employees.tsibble <- as_tsibble(employees, index = yearmonth)

covid19 <- read.csv('./covid19.csv', header = TRUE, na = '-', strip.white = TRUE, stringsAsFactors = TRUE)
colnames(covid19) <- c('category', 'status', 'date', 'value')
covid19 <- covid19[, c(3, 1, 2, 4)]
covid19$date <- as.Date(covid19$date, "%Y. %m. %d")
covid19.by.age <- covid19 %>% 
  filter(grepl('세', category)) %>% 
  filter(category != '세종')
covid19.by.age$value <- ifelse(is.na(covid19.by.age$value), 0, covid19.by.age$value)
wide.covid19.by.age <- tidyr::spread(covid19.by.age, category, value)

wide.covid19.by.age.ts = ts(wide.covid19.by.age[, 2:10], frequency = 365)
wide.covid19.by.age.xts <- as.xts(wide.covid19.by.age[, 3:10], order.by = wide.covid19.by.age$date)
wide.covid19.by.age.tsibble <- as_tsibble(wide.covid19.by.age, index = date)
```

# 시계열 forecasting Part II - 시계열 예측 모델

**A future like the past:**

시계열 예측의 가장 기본적인 가정은 과거의 패턴은 미래에도 계속된다는 가정이다. 이 가정은 단기 미래에서는 데이터가 발생되는 환경이 현재와 유사하기 때문에 불확실성이 작지만 장기 미래로 갈수록 데이터가 발생되는 환경이 달라질 가능성이 높아지면서 예측 데이터에 대한 불확실성이 높아질 수 밖에 없다.

이러한 이유때문에 시계열 예측은 외부 충격이나 원인모를 이유에 의한 갑작스런 데이터 흐름 변화를 예측해낼 수 없다는 한계를 지닌다. 그런 지점을 전환점(Turning Point)라고 한다. 이 전환점은 시계열 분석에 있어 중요한 부분이지만 전환점을 예측하기 위해서는 전통적인 시계열 분석 기법보다는 다른 기법을 활용해야 할 수 있다. [^forecasting-ii-1]

[^forecasting-ii-1]: <https://hbr.org/1971/07/how-to-choose-the-right-forecasting-technique>

본 장에서는 시계열 예측을 위한 모델을 설명하기 위해 forecast 패키지에서 제공하는 함수들을 이용한다. 여러가지 시계열 모델을 구축하고 성능평가를 통해 가장 효율적인 모델을 선정해야한다. 과거에는 많은 패키지에서 제공하는 다양한 함수를 사용하여 여러가지 모델을 각각 생성하고 성능평가를 위한 데이터를 생성하여 최선의 성능을 내는 모델을 채택하였다. 그러나 최근에는 여러가지 모델을 하나의 프레임워크에서 수행하여 가장 좋은 모델을 선정하는 방법이 사용된다. 따라서 이 장에서는 모델을 이해하고 다음 장에서 시계열 평가, 시각화를 위한 프레임워크를 소개하고자 한다.

## Simple 모델

simple 모델링 알고리즘은 Rob Hyndman의 'Forecasting : principals and practice'에서 그룹핑한 알고리즘과 명칭을 사용했다.[^forecasting-ii-2] 따라서 Simple 모델링이라는 명칭과 알고리즘들은 일반적인 분류는 아닐수 있다.

[^forecasting-ii-2]: <https://otexts.com/fpp2/>

사실 Simple 알고리즘을 보면 '이게 무슨 예측이야?'라고 생각할 수도 있다. 하지만 우리가 매우 쉽게 접하고 사용하는 '평균'이라는 것도 통계적 모델링에 하나라고 보면 Simple 알고리즘도 충분히 시계열 데이터의 모델링으로 볼 수도 있다.

Simple 모델링의 대부분은 매우 간단한 개념을 함수화 하여 미래 예측에 활용할 수 있도록 제작되었다. Simple 모델링에서 제시하는 대부분의 함수는 forecast 패키지(앞에서 설명한 Rob Hyndman이 주도하여 제작된 패키지임)에서 제공하는 함수를 위주로 설명하고자 한다. [^forecasting-ii-3]

[^forecasting-ii-3]: <https://otexts.com/fpp2/simple-methods.html>

### 평균 모델(forecast::meanf)

평균 모델은 우리가 흔히 알고 있는 평균이 앞으로의 미래에도 적용하는 방법이다. forecast 패키지에서는 meanf() 함수를 통해 시계열 데이터의 평균을 활용한 미래 예측값을 반환하는 함수를 제공한다. 이 함수에서는 평균 모델에 의한 점 예측값(Point Forecast)뿐 아니라 예측구간 80%와 95%를 산출해 준다. 매개변수를 설정함으로써 이 예측구간을 Bootstrap 방법을 통해 산출할 수도 있다. meanf() 함수의 입력 데이터는 숫자 벡터나 ts 클래스 객체를 사용한다. meanf()함수의 결과를 plot하기 위해서는 autoplot() 함수에 meanf() 결과 객체를 전달하여 ploting 할 수 있다.

```{r meanf, warning=FALSE, message=FALSE}
library(forecast)
summary(meanf(students.total.ts[,1]))
autoplot(meanf(students.total.ts[,1]))
autoplot(meanf(students.total.ts[,1], bootstrap = TRUE))
autoplot(meanf(employees.ts[,2]))
autoplot(meanf(employees.ts[,3]))
```

### 단순(Naive) 모델

단순(Naive) 모델은 시계열 측정값의 마지막 값이 지속될 것이라는 가정하에 향후 데이터값을 예측하는 모델이다. 이 모델은 경제 금융 시계열 모델에서 많이 사용된다. [^forecasting-ii-4] 앞선 평균 모델과 달리 Naive 모델의 예측구간은 예측 시간이 늘어날수록 범위가 늘어난다. 일반적으로 시계열 모델의 예측구간은 예측기간이 늘어날 수록 범위가 넓어지는 경향을 지닌다.

[^forecasting-ii-4]: <https://otexts.com/fpp2/simple-methods.html>

```{r naive}
summary(naive(students.total.ts[,1]))
autoplot(naive(students.total.ts[,1]))
summary(naive(employees.ts[,2]))
autoplot(naive(employees.ts[,2]))
summary(naive(employees.ts[,3]))
autoplot(naive(employees.ts[,3]))
```

### 계절성 단순(Seasonal Naive) 모델

계절성 단순(Seasonal Naive) 모델은 단순(Naive) 모델에서 계절성을 추가한 모델이다. 계절성(Seasonal Pattern)은 주기성(Cyclic Pattern)과 다르다. 계절성은 일정한 주기를 가지고 반복되는 패턴을 의미하지만 주기성은 패턴은 반복되지만 주기가 일정하지 않다는 점에서 다르다. 주기성의 주기는 일반적으로 2년보다 크기때문에 여러 연도에 걸쳐 나타나지만 계절성은 일반적으로 달력의 특성에 연관되어 주기를 갖는 경우가 일반적이다. [^forecasting-ii-5]

[^forecasting-ii-5]: <https://robjhyndman.com/hyndsight/cyclicts/>

```{r}
summary(snaive(students.total.ts[,1], 10))
autoplot(snaive(students.total.ts[,1], 10))
summary(snaive(employees.ts[,2], 10))
autoplot(snaive(employees.ts[,2], 10))
summary(snaive(employees.ts[,3], 10))
autoplot(snaive(employees.ts[,3], 10))
```

### Random Work 모델

랜덤 워크는 시간적으로 다음값이 시간적으로 현재값의 영향을 받는다는 이론이다. 주식의 예에서 보면 내일의 종가는 오늘의 종가에 랜덤한 값이 더해지거나 빼져서 결정되는 것과 같은 이치이다. 랜덤 워크에는 어제값 이외에 의미있는 정보가 없기 때문에 예측이 복잡하지 않다[^forecasting-ii-6]. 앞에서 설명한 Naive 모델은 마지막 값이 지속되는 예측인데 이것이 결국 랜덤 워크와 동일한 결과를 가지게 된다. 랜덤 워크 모델은 드리프트가 없는 모델과 드리프트가 존재하는 모델의 두가지 종류가 있다. 드리프트가 존재하는 모델은 랜덤워크 모델을 기반으로 하지만 예측값이 시간의 흐름에 따라 증가하거나 감소하는 모델이다.

[^forecasting-ii-6]: <https://robjhyndman.com/files/solutions.pdf>

```{r}
summary(rwf(students.total.ts[,1]))
autoplot(rwf(students.total.ts[,1]))
summary(rwf(employees.ts[,2]))
autoplot(rwf(employees.ts[,2]))
summary(rwf(employees.ts[,3]))
autoplot(rwf(employees.ts[,3]))

summary(rwf(students.total.ts[,1], drift = TRUE))
autoplot(rwf(students.total.ts[,1], drift = TRUE))
summary(rwf(employees.ts[,2], drift = TRUE))
autoplot(rwf(employees.ts[,2], drift = TRUE))
summary(rwf(employees.ts[,3], drift = TRUE))
autoplot(rwf(employees.ts[,3], drift = TRUE))
```

랜덤 워크는 시간적으로 하나 앞선 값과 현재값을 뺀 차이값들은 백색잡음이 되어야한다는 조건을 만족해야한다. 따라서 랜덤 워크 모델은 차분을 통해서백색잡음이 될 수도 있고 백색잡음은 누적합계를 통해서 랜덤 워크가 될 수 있다.

```{r randomwalk}
set.seed(345)
whitenoise <- ts(rnorm(100), start = 1)  ###  white noise simulation 데이터 생성
ts.plot(whitenoise)
whitenoise.to.randomwalk <- cumsum(whitenoise) ### white noise 데이터로 random walk 생성
ts.plot(whitenoise.to.randomwalk)
randomwalk.to.whitenoise <- diff(whitenoise.to.randomwalk) ### random walk에서 white noise 생성
ts.plot(randomwalk.to.whitenoise)
```

### Simple 모델 비교

위에서 설명한 모델들을 하나의 plot으로 그려보면 모델 간의 차이를 살펴볼 수 있다.

```{r simple_total}
autoplot(meanf(students.total.ts[,1], h = 10), PI = FALSE, series = 'Mean') + 
  autolayer(naive(students.total.ts[,1], h = 10), PI = FALSE, series = 'Naive') +
  autolayer(snaive(students.total.ts[,1], h = 10), PI = FALSE, series = 'Snaive') +
  autolayer(rwf(students.total.ts[,1], h = 10), PI = FALSE, series = 'RW') +
  autolayer(rwf(students.total.ts[,1], h = 10, drift = TRUE), PI = FALSE, series = 'RW with drift')

autoplot(meanf(employees.ts[,2], h = 10), PI = FALSE, series = 'Mean') + 
  autolayer(naive(employees.ts[,2], h = 10), PI = FALSE, series = 'Naive') +
  autolayer(snaive(employees.ts[,2], h = 10), PI = FALSE, series = 'Snaive') +
  autolayer(rwf(employees.ts[,2], h = 10), PI = FALSE, series = 'RW') +
  autolayer(rwf(employees.ts[,2], h = 10, drift = TRUE), PI = FALSE, series = 'RW with drift')

autoplot(meanf(employees.ts[,3], h = 10), PI = FALSE, series = 'Mean') + 
  autolayer(naive(employees.ts[,3], h = 10), PI = FALSE, series = 'Naive') +
  autolayer(snaive(employees.ts[,3], h = 10), PI = FALSE, series = 'Snaive') +
  autolayer(rwf(employees.ts[,3], h = 10), PI = FALSE, series = 'RW') +
  autolayer(rwf(employees.ts[,3], h = 10, drift = TRUE), PI = FALSE, series = 'RW with drift')
```

## Regression 모델

회귀 모델은 선형 회귀(Linear Regression), 비선형 회귀,(Non-linear Regression) 로지스틱 회귀(Logistic Regression) 등의 방법이 있다. 회귀 모델은 종속변수와 독립변수와의 관계를 가장 잘 나타내는 회귀방정식을 도출하여 미래 데이터에 대한 예측치를 생성하는 방법으로 아직도 머신러닝 알고리즘 중에 가장 많이 사용되는 알고리즘 중에 하나이다.[^forecasting-ii-7]

[^forecasting-ii-7]: 이기준 외, 인구지형변화에 따른 머신러닝 기반 고등교육 계열별 수요예측 모형 개발(2020), 한국교육개발원

본 문서에서는 R에서 회귀 알고리즘을 구현하는 방법을 다루지는 않고 시계열 데이터의 회귀 알고리즘을 적용하는 방법에 대해 설명하겠다. 시계열 데이터의 회귀 모델은 두가지로 구분할 수 있다. 첫번째는 두가지이상의 시계열 데이터(Multivariate) 간의 회귀 모델과 한가지 시계열 데이터(Univariate)의 시간에 따른 회귀모델이다. 사실 첫번째 모델의 경우는 일반적 회귀모델과 큰 차이는 없지만 사용하는 함수는 시계열 패키지에서 따로 제공된다. 두번째 모델의 경우는 시계열 데이터의 특성인 추세(trend)와 계절성(season), 반복성(cycle)을 회귀에 반영한다는 점에서 일반적 회귀와는 차이가 있다.

시계열 선형 회귀 모델은 데이터간의 관계를 가장 잘 나타내는 직선(Linear)을 산출하여 미래 데이터를 예측하는 방법이다. 선형 회귀 모델은 선형 방정식으로 표현되는데 직선의 기울기(Slope)와 Y 축 절편(Intercept)의 계수(Coefficient)가 산출된다. 시계열 데이터의 선형 회귀를 위해서 forecast 패키지에서 tslm()함수, timetk 패키지의 plot_time_series_regression() 함수(stats::lm() 함수를 사용하여 선형회귀 결과를 ploting하는 함수), modeltime 패키지(timetk 패키지의 모델링 패키지)의 linear_reg() 함수 등을 사용할 수 있다.

### tslm 함수(forecast 패키지)

forecast 패키지에서 제공하는 tslm() 함수는 시계열 선형회귀 모델을 위한 함수이다. tslm() 함수는 lm() 함수의 래퍼 함수(Wrapper)로 사용법은 비슷하고 시간축이 독립변수에 포함되지 않은 두개 혹은 두개 이상의 시계열 객체에 대한 선형회귀는 lm() 함수의 결과와 같다. 즉 시계열 데이터이지만 독립변수 시간이 포함되지 않는다면 시계열 데이터로써의 특성이 적용되지 않은 양 데이터간의 특성정보만으로 선형회귀 방정식이 얻어진다.

반면 시간을 독립변수로 하여 선형회귀 모형을 적용하기 위해서는 'trend', 'season' 키워드를 함수식의 독립변수에 적용해 줌으로써 시간에 대한 선형회귀 방정식을 얻을 수 있다. 'trend'는 시계열적인 추세를 반영하여 선형회귀 모델을 만들고 'season'은 시계열의 계절성을 반영하여 회귀모델을 만들게 되는데 두가지를 모두 고려할 때는 '+' 기호로 연결하여 사용할 수 있다. 이 과정에서 추가적인 독립변수를 추가할 수도 있는데 독립변수를 추가할 때도 '+' 기호를 사용하여 회귀모델을 만들 수 있다.

```{r tslm}
### 전체 학생수 예측 모델을 추세를 반영하여 생성
student.ts.lm <- tslm(students.total.ts[,1] ~ trend, data = students.total.ts)
summary(student.ts.lm)
student.ts.lm %>% forecast()  ### tslm 함수로 생성된 모델을 forecast()함수를 통해 예측값을 생성
student.ts.lm %>% forecast() %>% autoplot()
student.ts.lm <- tslm(students.total.ts[,3] ~ trend, data = students.total.ts)  ### 초등학생 학생수를 예측모델에 독립변수로 트랜드를 사용하는 선형 모델을 생성
student.ts.lm %>% forecast(h = 22) %>% autoplot()
student.ts.lm <- tslm(students.total.ts[,3] ~ students.total.ts[,2] + trend, data = students.total.ts)  ### 초등학생 학생수를 예측모델에 독립변수로 유치원 학생수와 트랜드를 사용하는 선형 모델을 생성
student.ts.lm %>% forecast(h = 22) %>% autoplot()
```

위의 예제에서 사용한 데이터는 연도별 학생수의 합계이다. 이 데이터와 같은 연도별 데이터는 계절성이 존재하지 않기 때문에 season 키워드를 사용하면 아래와 같이 에러를 낸다.

```{r error=TRUE}
student.ts.lm <- tslm(students.total.ts[,1] ~ trend + season, data = students.total.ts)
```

전체 취업자수와 교육서비스업 취업자수에 대한 선형회귀분석 모델과 plot은 다음과 같다.

```{r tslm1}
### 전체 취업자수를 추세(trend)만으로 선형 회귀분석
employee.total.ts.lm <- tslm(employees.ts[,2] ~ trend, data = employees.ts)
summary(employee.total.ts.lm)
employee.total.ts.lm %>% forecast()  ### tslm 함수로 생성된 모델을 forecast()함수를 통해 예측값을 생성
employee.total.ts.lm %>% forecast() %>% autoplot()
### 전체 취업자수를 추세(trend)와 계절성(season)으로 선형 회귀분석
employee.total.ts.lm <- tslm(employees.ts[,2] ~ trend + season, data = employees.ts)
summary(employee.total.ts.lm)
employee.total.ts.lm %>% forecast()  ### tslm 함수로 생성된 모델을 forecast()함수를 통해 예측값을 생성
employee.total.ts.lm %>% forecast() %>% autoplot()
### 교육분야 취업자수를 추세(trend)와 계절성(season)으로 선형 회귀분석
employee.total.ts.lm <- tslm(employees.ts[,3] ~ trend + season, data = employees.ts)
summary(employee.total.ts.lm)
employee.total.ts.lm %>% forecast()  ### tslm 함수로 생성된 모델을 forecast()함수를 통해 예측값을 생성
employee.total.ts.lm %>% forecast() %>% autoplot()
```

선형 회귀분석을 시행할 때 주의해야 할 점은 잔차가 백색 잡음이어야 한다는 점이다. 잔차의 자가회귀성이 존재하는 경우는 시계열적 특성을 여전히 지니고 있기 때문에 이를 제거할 필요가 있다. 다만 이 예측은 '잘못된' 것은 아니나 예측구간이 커지기 때문에 비효율적 예측 모델이 된다.[^forecasting-ii-8] 또한 예측에 적용해야할 시계열적 특성이 남아있다는 것을 잔차에서 확인할 수 있다.

[^forecasting-ii-8]: <https://otexts.com/fppkr/regression-evaluation.html>

아래의 예에서 보면 전체 학생수를 추세에 의해 선형 회귀분석을 시행한 경우 잔차는 자기 상관성을 지니고 있음을 볼 수 있다. checkresiduals() 함수를 사용하여 확인하는데 plot만 봐도 백색잡음이 아님을 확인할 수 있지만 백색잡음 테스트인 Breusch-Godfrey 테스트 결과(checkresiduals() 함수는 회귀모델에 대해서는 Breusch-Godfrey 테스트를, 나머지는 Ljung-Box 테스트를 시행한다.)의 p-value가 0.05보다 작기 때문에 자기상관성이 존재하여 백색잡음으로 볼 수 없다.

```{r tslm_resid}
checkresiduals(tslm(students.total.ts[,1] ~ trend, data = students.total.ts))
```

### plot_time_series_regression 함수(timetk 패키지)

timetk 패키지는 시계열 데이터를 핸들링하고 plotting 하는 데 주로 활용하는 패키지이다. 그래서 모델링을 위한 함수를 바로 제공하지는 않고 plotting 함수에서 회귀 모델을 호출하여 회귀 결과를 plotting 하는 함수를 제공한다. plot_time_series_regression() 함수에서 사용하는 선형회귀 함수에서도 trend, season 을 적용할 수 없다. 다만 ts 객체가 아닌 data.frame 객체를 사용할 수있다는 장점이 있다.

```{r lm_timetk}
plot_time_series_regression(.data = students %>% filter(지역규모 == '계'), 
                            .date_var = 연도, 
                            .formula = 학생수계 ~ 연도, 
                            .interactive = FALSE, 
                            .show_summary = TRUE) 
employees$date <- as.Date(as.yearmon(employees$time, "%Y. %m"))
###as.Date(paste0(employees[, 1], '. 01'), format = '%Y. %m. %d')

### plot_time_series_regression에 trend만 반영시
plot_time_series_regression(.data = employees, 
                            .date_var = time, 
                            .formula = total ~ as.numeric(date), 
                            .interactive = FALSE) 
### plot_time_series_regression에 trend, season(월)까지 반영시
plot_time_series_regression(.data = employees, 
                            .date_var = time, 
                            .formula = total ~ as.numeric(date) +
                            lubridate::month(date, label = TRUE), 
                            .interactive = FALSE) 
### plot_time_series_regression에 trend만 반영시
plot_time_series_regression(.data = employees, 
                            .date_var = time, 
                            .formula = employees.edu ~ as.numeric(date), 
                            .interactive = FALSE) 
# plot_time_series_regression에 trend, season(월)까지 반영시
plot_time_series_regression(.data = employees, 
                            .date_var = time, 
                            .formula = employees.edu ~ as.numeric(date) +
                              lubridate::month(date, label = TRUE), 
                            .interactive = FALSE) 
```

## 지수 평활(Exponential Smoothing) 모델

지수평활 모델은 1950년대에 제안된 모델로 랜덤 워크(Random Walk) 모델과 같이 시계열 적으로 최근의 값이 유지될 확률이 크다는 점에서 나온 모델이다. 다만 랜덤 워크 모델과 같이 마지막 값에 모든 가중치를 둬서 일정하게 유지하는 것이 아닌 현재와 가까운 과거에 더 많은 가중치를 주고 이들의 이동 평균값을 구해서 예측하는 방법이다. [^forecasting-ii-9]

[^forecasting-ii-9]: <https://otexts.com/fppkr/expsmooth.html>

최근의 데이터에 가중치를 높게 주기 때문에 추세, 계절성, 순환성이 심하지 않은 단기 데이터의 모델링에 적합한 방법이다. 추세나 계절성이 없는 데이터에 적합한 '단순 지수평활 모델(Simple Exponential Smoothign), 추세가 있는 데이터에 적합한 홀트(Holt) 모델, 추세와 계절성이 있는 데이터에 적합한 홀트-윈터(Holt-Winter) 모델 등이 있다.

지수 평활 모델에서 핵심적인 변수는 평활 계수이다. 평활 매개변수는 앞서 설명한 현재와 가까운 과거에 할당하는 가중치를 의미한다. 평활 매개변수은 보통 0에서 1사이의 변수인데 홀트 모델이나 홀트-윈터 모델에서는 추가적인 계수가 추가될 수 있다. 이고 이 가중치를 어떻게 설정하는 가에 따라 예측 모델의 성능도 달라질 수 있다.

필자는 처음 이 모델을 접했을때 왜 지수(Exponential)과 평활(Smoothing) 이라는 이름을 사용했는지 궁금했다. 평활 매개변수를 설명하는 과정에서 명칭에서 지수를 붙인 이유는 설명이 되겠지만 아직도 평활이라는 이름을 붙인 이유는 명쾌하게 이해되지는 않는다. 시계열 데이터에 대한 추세선을 부드럽게, 스무딩하게 만드는 모델이라고 생각이 되나 사실 홀트-윈터 모델을 보면 별로 부드럽지 않다는 느낌이 들어서 이 부분에 대해 잘 아시는 분은 알려주시길 부탁드린다.

### 단순 지수 평활 모델(Simple Exponentail Smoothing Model)

단순 지수 평활 모델은 추세, 계절성 등의 시계열적 특성이 비교적 약한 데이터에 적합한 예측 모델이다. 단순 지수 평활 모델을 사용하기 위해서는 우선 평활 계수를 설정해아한다.

평활 계수는 과거치에 대한 가중치로 현재에 가장 가까운 첫번째 과거 데이터에 대한 가중치이다. 이후 가중치 들은 1에서 가중치를 뺀 가중치(1-평활계수)로 설정하고 과거로 계속 갈수록 (1-평활계수)를 계속 곱해서 가중치를 할당한다. 평활 계수를 0.5로 가정하고 학생수 예에 적용해 보면 다음의 표와 같이 가중치가 설정되게 된다. 평활 계수가 지수형태로 계산되기 때문에 평활계수의 합은 1이 될 수 없다.

| 연도 | 가중치(평활계수 = 0.5)                       |
|:----:|----------------------------------------------|
| 2020 | 0.5                                          |
| 2019 | 0.25 = (1 - 0.5)                             |
| 2018 | 0.125 = (1 - 0.5) \* (1 - 0.5)               |
| 2017 | 0.0625 = (1 - 0.5) \* (1 - 0.5) \* (1 - 0.5) |
| ...  | ...                                          |

#### forecast::ses() 함수

단순 지수 평활 모델을 적용하는 방법은 forecast 패키지의 ses() 함수를 사용하면 모델을 구축할 수 있다. ses() 함수에서는 평활 계수를 alpha 매개변수를 통해 설정할 수 있지만 설정하지 않으면 자동으로 계산하여 설정해준다. ses() 함수는 뒤에서 설명하는 홀트 모델, 홀트-윈터 모델도 beta와 gamma 매개변수를 통해 생성할 수 있다. ses() 함수를 통해 생성되는 모델은 몇가지 특성값을 가지는데 앞에서 설명한 평활계수가 alpha로 표현되고 초기상태값인 l 값이 나타난다. 단순 지수 평활 모델은 한단계씩 예측해나가는 방법(One Step Forecast)이기 때문에 초기값인 l값부터 시작하여 한단계 앞 값을 예측하고 또 다음 단계를 예측하는 방법으로 수행된다. l 값을 산출하는 방법은 Rob Hyndman의 저서에서 확인할 수 있다.[^forecasting-ii-10] 이는 ses() 모델을 summary() 함수를 통해 실행시키면 확인이 가능하다.

[^forecasting-ii-10]: <https://otexts.com/fpp2/ses.html>

```{r ses, message=FALSE, warning=FALSE}
### 전체 학생수에 대한 Simple Exponential Smoothing
ses(students.total.ts[,1])
autoplot(students.total.ts[,1]) + 
  autolayer(fitted(ses(students.total.ts[,1])), series = 'ses 적합값') +
  autolayer(ses(students.total.ts[,1]))
summary(ses(students.total.ts[,1]))
ses(students.total.ts[,1], alpha = 0.5)
ses(students.total.ts[,1], alpha = 0.5) %>% autoplot()

### 전체  취업자수에 대한 Simple Exponential Smoothing
autoplot(employees.ts[,2]) + 
  autolayer(fitted(ses(employees.ts[,2])), series = 'ses 적합값') +
  autolayer(ses(employees.ts[,2]))

### 코로나 신규확진자수(0-9세)에 대한 Simple Exponential Smoothing
autoplot(wide.covid19.by.age.ts[,2]) + 
  autolayer(fitted(ses(wide.covid19.by.age.ts[,2])), series = 'ses 적합값') +
  autolayer(ses(wide.covid19.by.age.ts[,2]))
```

평활 계수가 클수록 데이터 변화에 빠르게 반응하여 예측의 감응도가 높지만 평활계수가 작으면 데이터의 변화에 느리게 반응하여 예측의 안정성이 높아진다 [^forecasting-ii-11]

[^forecasting-ii-11]: <https://m.blog.naver.com/PostView.nhn?blogId=sigmagil&logNo=221502514892&proxyReferer=https:%2F%2Fwww.google.com%2F>

```{r ses_alpha, message=FALSE, warning=FALSE}
### 전체 학생수의 alpha 값에 따른 적합치와 예측치의 변화
autoplot(students.total.ts[,1], color = 'black') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.1)), series = 'alpha = 0.1') +
  autolayer(ses(students.total.ts[,1], alpha = 0.1, PI = FALSE), series = 'alpha = 0.1') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.2)), series = 'alpha = 0.2') + 
  autolayer(ses(students.total.ts[,1], alpha = 0.2, PI = FALSE), series = 'alpha = 0.2') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.3)), series = 'alpha = 0.3') +
  autolayer(ses(students.total.ts[,1], alpha = 0.3, PI = FALSE), series = 'alpha = 0.3') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.4)), series = 'alpha = 0.4') +
  autolayer(ses(students.total.ts[,1], alpha = 0.4, PI = FALSE), series = 'alpha = 0.4') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.5)), series = 'alpha = 0.5') +
  autolayer(ses(students.total.ts[,1], alpha = 0.5, PI = FALSE), series = 'alpha = 0.5') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.6)), series = 'alpha = 0.6') +
  autolayer(ses(students.total.ts[,1], alpha = 0.6, PI = FALSE), series = 'alpha = 0.6') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.7)), series = 'alpha = 0.7') +
  autolayer(ses(students.total.ts[,1], alpha = 0.7, PI = FALSE), series = 'alpha = 0.7') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.8)), series = 'alpha = 0.8') +
  autolayer(ses(students.total.ts[,1], alpha = 0.8, PI = FALSE), series = 'alpha = 0.8') +
  autolayer(fitted(ses(students.total.ts[,1], alpha = 0.9)), series = 'alpha = 0.9') +
  autolayer(ses(students.total.ts[,1], alpha = 0.9, PI = FALSE), series = 'alpha = 0.9')
```

#### stats::HoltWinters() 함수

R에서 기초 통계 패키지로 제공하는 stat 패키지에서 지수 평활 모델을 구축할 수 있는 HoltWinters() 함수를 제공한다. 다음절에서 소개하겠지만 HoltWinter 모델은 지수 평활 모델에서 추세와 계절성을 가진 데이터를 대상으로 구축하는 모델이다. 하지만 stats 패키지에서는 HoltWinters() 함수에 매개변수를 조절함으로써 단순지수평활 모델, 홀트 모델, 홀트-윈터 모델을 각각 구축할 수 있다. HoltWinters() 함수의 beta(추세), gamma(계절성) 매개변수를 모두 FALSE로 설정함으로써 단순 지수 평활 모델을 구축할 수 있다. 계산방식의 차이로 인해 forecast::ses() 함수와는 다소 차이가 난다.

```{r simple_holtwinters}
### 전체 학생수에 대한 Simple Exponential Smoothing modeling
HoltWinters(students.total.ts[,1], beta = F, gamma = F)
plot(HoltWinters(students.total.ts[,1], beta = F, gamma = F))
HoltWinters(students.total.ts[,1], alpha = 0.1, beta = F, gamma = F)
plot(HoltWinters(students.total.ts[,1], alpha = 0.1, beta = F, gamma = F))

### 전체  취업자수에 대한 Simple Exponential Smoothing modeling
plot(HoltWinters(employees.ts[,2], beta = F, gamma = F))

### 코로나 신규확진자수(0-9세)에 대한 Simple Exponential Smoothing modeling
plot(HoltWinters(wide.covid19.by.age.ts[,2], beta = F, gamma = F))
```

### 홀트(Holt) 모델

홀트(holt) 모델은 지수 평활 모델을 확장하여 추세를 반영하는 모델이다. 홀트 모델은 추세조정 지수평활법이나 이중 지수 평활법으로 해석되기도 한다. 추세를 반영하기 위해 평활 계수인 alpha와 추세 기울기 값 beta를 사용하여 모델을 세운다. 평활 계수 값과 마찬가지로 추세 기울기 값도 0과 1사이의 값을 지니고 이 값을 반영한 이동평균을 통해 예측값을 산출한다.

#### forecast::holt() 함수

홀트 모델은 앞선 단순 지수 평활 모델에 사용했던 ses() 함수에 추세 기울기 값인 beta 값을 추가하여 사용할 수도 있고 forecast 패키지에서 제공하는 holt() 함수를 사용하여 모델을 생성할 수도 있다. 다만 alpha, beta 등의 매개변수를 지정하지 않으면 자동 계산되어 적절한 값이 사용된다.

```{r holt}
### 전체 학생수에 대한 Holt modeling
autoplot(students.total.ts[,1]) + 
  autolayer(fitted(holt(students.total.ts[,1])), series = '적합값') +
  autolayer(holt(students.total.ts[,1]), series = '예측값')
summary(holt(students.total.ts[,1]))

### 전체  취업자수에 대한 Holt modeling
autoplot(employees.ts[,2]) + 
  autolayer(fitted(holt(employees.ts[,2])), series = '적합값') +
  autolayer(holt(employees.ts[,2]), series = '예측값')

### 교육서비스업  취업자수에 대한 Holt modeling
autoplot(employees.ts[,3]) + 
  autolayer(fitted(holt(employees.ts[,3])), series = '적합값') +
  autolayer(holt(employees.ts[,3]), series = '예측값')

### 코로나 신규확진자수(0-9세)에 대한 Holt modeling
autoplot(wide.covid19.by.age.ts[,2]) + 
  autolayer(fitted(holt(wide.covid19.by.age.ts[,2])), series = '적합값') +
  autolayer(holt(wide.covid19.by.age.ts[,2]), series = '예측값')
```

홀트 모델은 위와 같이 일정한 증가, 감소가 나타난다. 추세가 증가 추세이면 예측값이 계속 증가하게 되고 감소추세이면 계속 감소하게 된다. 특히 감소추세 일때 계속 감소하면 어느 순간 음수값을 가질수도 있다. 따라서 감소 추세가 있는 경우 어느정도에서 감소추세를 지연시킬 필요가 있다. holt() 함수에서는 damped 매개변수를 통해 감소추세를 지연시킬 수 있다.

```{r holt_damped}
### 전체 학생수에 대한 Holt modeling 비교
autoplot(students.total.ts[,1]) + 
  autolayer(fitted(holt(students.total.ts[,1])), series = 'holt') +
  autolayer(fitted(holt(students.total.ts[,1], damped = TRUE)), series = 'holt damped') +
  autolayer(holt(students.total.ts[,1]), series = '예측', PI = FALSE) + 
  autolayer(holt(students.total.ts[,1], damped = TRUE), series = 'damped 예측', PI = FALSE)

### 전체  취업자수에 대한 Holt modeling 비교
autoplot(employees.ts[,2]) + 
  autolayer(fitted(holt(employees.ts[,2])), series = 'holt') +
  autolayer(fitted(holt(employees.ts[,2], damped = TRUE)), series = 'holt damped') +
  autolayer(holt(employees.ts[,2]), series = '예측', PI = FALSE) + 
  autolayer(holt(employees.ts[,2], damped = TRUE), series = 'damped 예측', PI = FALSE)

### 코로나 신규확진자수(0-9세)에 대한 Holt modeling 비교
autoplot(wide.covid19.by.age.ts[,2]) + 
  autolayer(fitted(holt(wide.covid19.by.age.ts[,2])), series = 'holt') +
  autolayer(fitted(holt(wide.covid19.by.age.ts[,2], damped = TRUE)), series = 'holt damped') +
  autolayer(holt(wide.covid19.by.age.ts[,2], h = 20), series = '예측', PI = FALSE) + 
  autolayer(holt(wide.covid19.by.age.ts[,2], h = 20, damped = TRUE), series = 'damped 예측', PI = FALSE)
```

추세 기울기 값에 따른 변동은 아래 plot과 같이 나타난다. 사실상 추세 기울기 값은 결과값에 큰 차이를 나타내지 않는다.

```{r holt_beta, message=FALSE, warning=FALSE}
autoplot(employees.ts[,2]) + 
  autolayer(fitted(holt(employees.ts[,2], beta = 0.1)), series = 'beta = 0.1') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.2)), series = 'beta = 0.2') + 
  autolayer(fitted(holt(employees.ts[,2], beta = 0.3)), series = 'beta = 0.3') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.4)), series = 'beta = 0.4') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.5)), series = 'beta = 0.5') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.6)), series = 'beta = 0.6') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.7)), series = 'beta = 0.7') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.8)), series = 'beta = 0.8') +
  autolayer(fitted(holt(employees.ts[,2], beta = 0.9)), series = 'beta = 0.9')
```

#### stats::HoltWinters() 함수

앞서 설명한 바와 같이 R에서 기초 통계 패키지로 제공하는 stat 패키지에서 홀트 모델을 구축하기 위해서는 HoltWinters() 함수를 제공한다. stats 패키지의 HoltWinters() 함수 매개변수인 gamma(계절성) 매개변수를 FALSE로 설정함으로써 홀트 모델을 구축할 수 있다. 계산방식의 차이로 인해 forecast::holt() 함수와는 다소 차이가 난다.

```{r holt_holtwinters}
### 전체 학생수에 대한 Holt modeling
HoltWinters(students.total.ts[,1], gamma = F)
plot(HoltWinters(students.total.ts[,1], gamma = F))
HoltWinters(students.total.ts[,1], alpha = 0.1, gamma = F)
plot(HoltWinters(students.total.ts[,1], alpha = 0.1, gamma = F))

### 전체  취업자수에 대한 Holt modeling
plot(HoltWinters(employees.ts[,2], gamma = F))

### 코로나 신규확진자수(0-9세)에 대한 Holt modeling
plot(HoltWinters(wide.covid19.by.age.ts[,2], gamma = F))
```

### 홀트-윈터(Holt-Winter) 모델

홀트-윈터(Holt-Winter) 모델은 단순 지수 평활 모델을 확장하여 추세와 계절성을 반영하는 모델이다. 홀트-윈터 모델은 ses 모델의 alpha, 홀트 모델의 beta에 계절 매개변수인 gamma까지 포함하기 때문에 삼중 지수 평활법이나 계절조정 지수 평활법이라고도 한다.

홀트-윈터 모델도 앞선 홀트 모델과 같이 ses() 함수에 추세 기울기 값인 beta 값과 계절 변수인 gamma 값을 추가하여 사용할 수도 있고 forecast 패키지에서 제공하는 hw() 함수를 사용하여 모델을 생성할 수도 있다. 다만 alpha, beta 등의 매개변수를 지정하지 않으면 자동 계산되어 적절한 값이 사용된다.

#### forecast::hw() 함수

홀트-윈터 모델은 가산법(additive)와 승산법(multiplicative)의 두가지 방법이 있다.

```{r hw, message=FALSE, warning=FALSE}
autoplot(employees.ts[,2]) + 
  autolayer(fitted(hw(employees.ts[,2])), series = 'hw 적합값') +
  autolayer(hw(employees.ts[,2], seasonal = 'additive'), PI = FALSE, series = 'additive') + 
  autolayer(hw(employees.ts[,2], seasonal = 'multiplicative'), PI = FALSE, series = 'multiplicative')
summary(hw(employees.ts[,2]))

autoplot(employees.ts[,3]) + 
  autolayer(fitted(hw(employees.ts[,3])), series = 'hw 적합값') +
  autolayer(hw(employees.ts[,3], seasonal = 'additive'), PI = FALSE, series = 'additive') +
  autolayer(hw(employees.ts[,3], seasonal = 'multiplicative'), PI = FALSE, series = 'multiplicative')
summary(hw(employees.ts[,3]))
```

가산법은 계절성의 변화 비교적 일정하게 나타날때 사용하는 방법이고 승산법은 계절성의 진폭이 추세에 비례하여 변동이 있을때 사용하는 방법이다. 따라서 미래 예측치를 산출할 때도 가산법은 예측치가 크게 변동되지 않지만 승산법은 먼 미래일 수록 예측값이 커지게 된다.

가산법과 승산법을 사용하는 방법은 hw() 함수에서 seasonal 매개변수를 통해 설정할 수 있다. seasonal 매개변수를 'additive'로 설정하면 가산법, 'multiplicative'를 설정하면 승산법을 사용하여 모델이 구축된다.

사실상 가산법과 승산법 중 어느 방법을 선택해야하는 지를 선택하는 방법은 시각적으로 확인하거나 다음 장에서 설명할 모델 성능 비교 방법을 통해 선택해야한다.

#### stats::HoltWinters() 함수

```{r hw_holtwinters}
### 전체  취업자수에 대한 Holt modeling
HoltWinters(employees.ts[,2])
plot(HoltWinters(employees.ts[,2]))
plot(HoltWinters(employees.ts[,3]))
```

### ETS 모델

ETS 모델은 Error, Trend, Season의 앞글자만 따서 만들었다고도 하고 ExponenTial Smoothing의 약자라고도 한다. 앞서 설명한 지수 평활 모델을 잔차(실제값 - 적합값)로 보정한 모델이다. ETS 모델은 모델을 구성하는 방법에 따라 여러가지 모델로 구분될 수 있다. 각 모델은 실 데이터의 측정식(measurement equation)과 측정식에서 추출된 추세, 계절성 등을 통해 추정되는 미래 예측값에 대한 상태식(state equation)에 따라 결정되는데 이를 상태공간모델(status space model)이라고 한다.[^forecasting-ii-12]

[^forecasting-ii-12]: <https://otexts.com/fppkr/ets.html>

상태공간모델에 의한 ETS 모델은 Error에 의한 가법 보정(A), 승법보정(M), 추세에 따른 가법 방법(A), 감쇄 가법 방법(Ad), 추세 없음(N), 계절성에 따른 계절성 없음(N), 가법 계절성(A), 승법 계절성(M)으로 구분된다. 이 8가지 방법을 활용하여 최종 ETS 모델을 결정할 수 있는데 모든 조합이 모델이 되지는 않는다.

forecast의 ets() 함수에는 상태공간모델을 지정할 수 있지만 ets() 함수에서 자동적으로 선정해준다. ets 모델을 autoplot에 적용시키면 각각의 성분별로 plot을 확인할 수 있다.

```{r ets}
ets(students.total.ts[,1])  ### ETS(A,Ad,N)로 선정 error는 A, trend는 Ad, season은 N
ets(students.total.ts[,1]) %>% autoplot()  ### 전체 학생수에 대한 ets 모델 ploting
ets(students.total.ts[,1]) %>% forecast() %>% autoplot() ### 전체 학생수에 대한 예측치 ploting
ets(employees.ts[,2])  ### ETS(M,Ad,A)로 모델 선정
ets(employees.ts[,2]) %>% autoplot()
ets(employees.ts[,2]) %>% forecast() %>% autoplot()
ets(wide.covid19.by.age.ts[,2])  ### ETS(A,N,N)로 모델 선정
ets(wide.covid19.by.age.ts[,2]) %>% autoplot()
ets(wide.covid19.by.age.ts[,2]) %>% forecast() %>% autoplot() 
```

## ARIMA 모델

앞서 설명한 지수평활 모델은 이번 절에서 설명하는 ARIMA 모델과 함께 시계열 예측 모델에서 가장 많이 사용되어온 모델이다. ARIMA는 AutoRegression Integrated Moving Average의 앞글자만 딴 이름이다. 지수 평활 모델은 주어진 데이터에서 추세와 계절성을 계량화한 모델이지만 ARIMA 모델은 이름에서도 나타나듯이 자기상관과 이동평균을 수식화한 모델이다. 사실 ARIMA 모델은 ARMA(AutoRegression Moving Average)을 기반으로 한 모델이지만 ARMA 모델은 정상성 시계열에 한한 모델이기 때문에 비정상성 데이터를 정상화하는 단계를 포함하여 ARIMA 모델로 구현된다.[^forecasting-ii-13]

[^forecasting-ii-13]: <https://icim.nims.re.kr/post/easyMath/68>

ARIMA 모델은 arima(p, d, q)로 표현되는데 p는 AR모델의 차수, d는 비정상성 시계열을 정상성 시계열로 변환하기 위한 차분 차수, q는 이동평균 차수를 의미한다. 결국 ARIMA(p, d, q)모델은 데이터를 정상성 시계열로 만들기 위해 d번 차분한 데이터에 ARMA(p, q)모델을 적용하는 것과 동일하다.

### 자기회귀모델(AutoRegressive Model)

머신러닝을 공부할 때 가장 먼저 배우는 모델이 선형회귀모델이다. 선형회귀모델은 독립변수와 종속변수를 분리하고 두 변수간의 상관관계를 분석하여 모델링을 한다 . 앞선 장에서 시계열 선형회귀분석을 설명하였는데 이때의 독립변수는 시간이었고 종속변수는 예측을 원하는 변수를 설정하였다.

그러나 AR모델은 독립변수고 종속변수가 모두 하나의 변수를 사용한다는 점에서 일반 회귀모델과 다르다. 과거의 자기자신의 데이터와 현재 데이터간의 상관관계를 분석하여 회귀모델을 세우는 것이 AR 모델이다.

AR(p) 모델은 자기 상관관계가 lag p까지 영향을 미치는 모델이다. AR(1)은 자신의 데이터에 lag 1을 취한 데이터간의 회귀분석 모델이고 AR(2)는 자신의 데이터에 lag 1과 lag 2 데이터 간의 다중 회귀분석 모델이다. 따라서 AR(1) 모델은 회귀계수가 하나이고 AR(2) 모델은 회귀계수가 2개이므로 AR(p) 모델은 회귀계수가 p개 존재하게 된다.

다음의 예는 자기회귀모델을 생성하고 ploting하는 예를 보이고 있다. arima.sim() 함수는 ARIMA 모형에 따른 랜덤 데이터를 생성하는 함수이다.

```{r ARmodel}
library(tseries)
set.seed(345) 
arima100 <- arima.sim(model = list(order = c(1, 0, 0), ar = 0.9), n = 200)   ### ARIMA(1,0,0)에 AR(1)의 회귀계수가 0.9인 데이터 200개 생성
arima100 %>% autoplot(main = 'AR(1) model')
kpss.test(arima100)   ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 크므로 정상성, 차분 불필요
ndiffs(arima100, test = 'kpss') ### 비정상 제거를 위한 차분수 - 0이 나오므로 차분 불필요

set.seed(345)
arima110 <- arima.sim(model = list(order = c(1, 1, 0), ar = 0.9), n = 200) 
arima110 %>% autoplot(main = 'AR(1), 차분 1 model')
kpss.test(arima110)  ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 작으므로 정상성, 차분 필요
ndiffs(arima110, test = 'kpss')   ### 비정상성을 제거하기 위해 필요한 차분수
```

ARIMA(1, 0, 0)의 ACF, PACF plot은 다음과 같이 나타난다. acf plot을 보면 자기 상관성이 전반적으로 높고 천천히 감소하는 형태(Tail off)를 보인다. 그리고 pacf plot은 lag 1에서 매우 높지만 2에서부터는 끊어진다.(cut off) ARIMA(1, 1, 0)도 유사한 형태를 나타낸다.

```{r ARmodel_ACF}
arima100 %>% ggtsdisplay()
```

### 이동평균 모델(Moving Average Model)

이동 평균을 가장 많이 볼 수 있는 응용은 주식 plot이다. 주식 plot에서는 3일 이동평균, 5일 이동평균, 10일 이동평균등 다양한 이동평균을 통해 해당 주식 주가의 전반적인 흐름을 파악한다.

보통 우리는 평균을 데이터의 전체합을 데이터의 갯수로 나누어 산출한다. 데이터의 전체적 흐름을 평균이라는 하나의 레벨로 표현하게 되는데 흔히 시계열 데이터에서도 마찬가지로 산출한다. 그러나 이 경우 오래된 데이터 일수록 최근 추세나 경향이 미치는 영향보다는 과거 추세가 강하게 들어가게 되므로 현재 데이터 추세나 경향에 둔감해지는 경향이 있다. 따라서 이동 평균은 최근의 데이터들에 대한 평균치를 산출함으로써 과거보다는 현재에 흐름에 맞는 평균을 산출할 수 있다는 장점이 있다. 이 이동 평균을 연속적으로 ploting 하면 데이터의 추세과 경향을 파악할 수 있다.

이동 평균 모델은 MA(q)로 표현하는데 q는 이동평균을 산출하는 차수를 의미한다. q가 1인 경우는 기준 시점값과 바로 이전값의 평균, 2인경우는 기준 시점값과 이전, 차이전 값과의 평균을 의미한다. 기준 시점값은 시계열 적으로 과거값으로 하나씩 이동할 수 있고 시계열 초기값까지 이동하면 이동평균 산출은 끝난다.

이동 평균 모델에서 하나 주의해야 할점은 이동 평균 모델의 계수를 적용하는 독립 변수가 오차항이라는 점이다. 앞선 자기회귀모델에서는 자기회귀계수를 자기자신의 lag 차수값에 적용하였지만 이동 평균 모델은 이동평균 계수를 오차항에 적용시킨다. (이해가 어렵지만 원리를 알고싶다면 참고문헌[^forecasting-ii-14]을 참조하라)

[^forecasting-ii-14]: <https://otexts.com/fppkr/MA.html>

```{r MAmodel}
set.seed(345) 
arima001 <- arima.sim(model = list(order = c(0, 0, 1), ma = 0.9), n = 200)   ### ARIMA(1,0,0)에 AR(1)의 회귀계수가 0.9인 데이터 200개 생성
arima001 %>% autoplot(main = 'MA(1) model')
arima001 %>% ggtsdisplay()
kpss.test(arima001)   ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 크므로 정상성, 차분 불필요
ndiffs(arima001, test = 'kpss') ### 비정상 제거를 위한 차분수 - 0이 나오므로 차분 불필요

set.seed(345)
arima011 <- arima.sim(model = list(order = c(0, 1, 1), ma = 0.9), n = 200) 
arima011 %>% autoplot(main = 'MA(1), 차분 1 model')
kpss.test(arima011)  ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 작으므로 정상성, 차분 필요
ndiffs(arima011, test = 'kpss')   ### 비정상성을 제거하기 위해 필요한 차분수
```

ARIMA(0, 0, 1)의 ACF, PACF plot은 다음과 같이 나타난다. AR(1)모델의 acf는 점차 감소(tail off)하였고 pacf는 1에서 절단(cut off)되었지만 MA(1)모델에서는 acf plot이 1에서 절단(cut off)되고 pacf plot은 +와 -를 반복하지만 전반적으로 감소(tail off)하고 있다.

```{r MAmodel_ACF}
arima001 %>% ggtsdisplay()
```

### ARIMA 모델 결정

ARIMA 모델을 사용하기 위해서는 p, d, q의 차수를 결정하는 것이 매우 중요하다. 차수를 결정하는 방법은 앞서 설명한 acf, pacf를 보고 판단할 수 있는데 forecast 패키지의 auto.arima() 함수에서는 자동으로 p, d, q의 차수를 결정해주기도 한다.

하지만 ARIMA 모델의 전반적인 동작을 이해하기 위해서는 acf와 pacf를 확인하여 모델을 결정하는 방법을 알아둘 필요가 있다.

앞의 예제에서 AR(1)과 MA(1)의 ACF와 PACF plot을 보았는데 두 경우가 비슷하지만 다른 특성이 있다. AR(1) 모델의 경우는 ACF plot이 점차 감소(tail off)하고 PACF plot의 절단(cut off) 차수가 1이었다. 반면 MA(1)의 경우는 ACF plot의 절단(cut off) 차수가 1이었고 PACF plot이 점차 감소(tail off)하였다.

위의 예제에서 보듯이 AR모델은 ACF plot이 점차 감소하며 PACF plot의 절단 차수가 p값을 의미한다. 반면 MA 모델은 PACF plot이 점차 감소하며 ACF plot의 절단차수가 q값을 의미한다. 이 과정에서 비정상성 시계열을 정상성 시계열로 만들기 위해 차분을 적용하는데 차분의 적용차수가 d값을 의미한다. 만약 AR과 MA가 동시에 나타나는 모델의 경우는 다음의 예에서 보듯이 ACF와 PACF가 모두 점차 감소하는 형태를 보인다.

반면 아래의 예제와 같이 p와 q가 모두 0보다 큰 경우는 ACF와 PACF plot으로 모델을 결정하는 것이 적절하지 않을 수 있다. [^forecasting-ii-15] 이 경우에는 먼저 차분을 통해 정상성 시계열로 만든 후 ACF와 PACF를 다시 확인해봐야 하고 이 경우에도 적절한 차수를 찾기 어렵다면 여러가지 경우수를 설정하고 AIC, BIC, RMSE 등의 성능 분석 수치를 통해 가장 좋은 모델을 선정해야 한다. 이와 관련된 내용은 다음 장에서 다루겠다.

[^forecasting-ii-15]: <https://otexts.com/fpp2/non-seasonal-arima.html>

```{r ARMAmodel}
set.seed(345) 
arima101 <- arima.sim(model = list(order = c(1, 0, 1), ar = 0.9, ma = 0.9), n = 200)   ### ARIMA(1,0,0)에 AR(1)의 회귀계수가 0.9인 데이터 200개 생성

arima101 %>% autoplot(main = 'AR(1), MA(1) model')
arima101 %>% ggtsdisplay()
```

ARIMA 모델을 학생수 시계열 데이터, 취업자수 시계열 데이터, 코로나 확진자 시계열 데이터에 적용해보면 다음과 같다. 앞서 설명한 바와 같이 forecast 패키지에서는 ARIMA모델을 자동으로 결정해주는 함수인 auto.arima()를 제공한다.

학생수 데이터를 ARIMA 모델에 적용하면 ACF와 PACF로 비교적 확실하게 확인이 가능한 모델을 선정할 수 있다.

```{r ARIMA_students}
auto.arima(students.total.ts[,1])  ### 학생수의 ARIMA모형은 ARIMA(1, 2, 0)으로 선정됨
students.total.ts[,1] %>% ggtsdisplay()  ### ACF가 tail off이고 PACF가 1에서 cut off 이므로 ARMA(1,0)모델
kpss.test(students.total.ts[,1])  ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 작으므로 정상성, 차분 필요
ndiffs(students.total.ts[,1], test = 'kpss')   ### 비정상성을 제거하기 위해 필요한 차분수가 2이므로 최종 모델은 ARIMA(1, 2, 0)
auto.arima(students.total.ts[,1]) %>% forecast() %>% autoplot()
```

전체 취업자 수는 계절성을 지니기 때문에 다음의 절에서 설명한다. 교육서비스업 취업자는 다음과 같이 ARIMA 모델이 결정된다.

```{r ARIMA_employees}
auto.arima(employees.ts[, 3]) ### 교육서비스업 취업자수의 ARIMA모형은 ARIMA(0, 1, 0)으로 선정됨
kpss.test(employees.ts[, 3])  ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 작으므로 비정상성, 차분 필요
ndiffs(employees.ts[, 3], test = 'kpss')   ### 비정상성을 제거하기 위해 필요한 차분수가 1
diff(employees.ts[, 3]) %>% ggtsdisplay()  ### 1차 차분을 해본 결과 ACF, PACF 모두 절단(Cut off)이므로 ARMA(0,0)
auto.arima(employees.ts[, 3]) %>% forecast() %>% autoplot()  ### ARIMA(0,1,0)은 랜덤 워크 모델
```

코로나 확진자 데이터의 자동 ARIMA 모형은 (2, 1, 1)로 나타난다. kpss.test와 ndiffs를 통해 차분이 1인 경우 정상성이 되는 것을 확인할 수 있으나 p, q값이 모두 0보다 큰 수이기 때문에 ACF와 PACF plot으로 차수를 결정하는 것이 적절하지 않다.

```{r ARIMA_covid}
auto.arima(wide.covid19.by.age.ts[,2]) ### 교육서비스업 취업자수의 ARIMA모형은 ARIMA(0, 1, 0)으로 선정됨
kpss.test(wide.covid19.by.age.ts[,2])  ### kpss 테스트를 통해 생성된 데이터가 정상성인지 테스트 - 0.05보다 작으므로 비정상성, 차분 필요
ndiffs(wide.covid19.by.age.ts[,2], test = 'kpss')   ### 비정상성을 제거하기 위해 필요한 차분수가 1
diff(wide.covid19.by.age.ts[,2]) %>% ggtsdisplay()  ### 1차 차분을 해본 결과 ACF, PACF 모두 절단(Cut off)이므로 ARMA(0,0)
```

### Seasonal ARIMA 모델

위에서 살펴본 모델은 비계절성 ARIMA 모델이었다. 계절성을 지니는 데이터는 비계절성 ARIMA 모델로는 적절히 모델링이 어렵기 때문에 계절성 ARIMA 모델에 적합시켜야 한다. 계절성 ARIMA는 비계절성 ARIMA의 p, d, q 차수 외에 계절성 차수인 P, D, Q와 관측주기 m을 추가적으로 결정해야 하고 ARIMA(p, d, q)(P, D, Q)m으로 표기한다.

```{r ARIMA_seasonal}
employees.ts[, 2] %>% ggtsdisplay() ### 전체 취업자수는 ACF plot을 볼때 12주기마다 계절성이 있음.
summary(auto.arima(employees.ts[, 2]))  ### 학생수의 ARIMA모형은 ARIMA(0, 1, 0)(0, 1, 1)[12]으로 선정됨

employees.ts.seasadj <- employees.ts[, 2] %>% stl(s.window='periodic') %>% seasadj()  ### 계절성을 제외
employees.ts.seasadj %>% ggtsdisplay() ### 계절성을 제외한 데이터는 비정상성 있음
diff(employees.ts.seasadj) %>% ggtsdisplay() ### 계절성 제외 데이터를 1차분한 결과는 ARMA(0,0)

employees.ts[, 2] %>% diff(lag =12) %>% ggtsdisplay()  ### 계절성이 있기 때문에 계절성(12)로 차분 데이터를 구해 계절성을 점검
employees.ts[, 2] %>% diff(lag =12) %>% kpss.test()  ###계절성 차분 데이터가 비정상성
employees.ts[, 2] %>% diff(lag =12) %>% ndiffs() ### 계절성 차분 데이터의 차분 수를 구함
employees.ts[, 2] %>% diff(lag =12) %>% diff() %>% kpss.test()  ### 계절성 차분 데이터의 1차 차분 데이터는 정상성
employees.ts[, 2] %>% diff(lag =12) %>% diff() %>% ggtsdisplay()  ### 계절성 차분 데이터의 ACF와 PACF를 확인하면 ARMA(0,0)

arima010010 <- arima(employees.ts[, 2], order = c(0,1,0), seasonal = c(0,1,0))
arima010011 <- arima(employees.ts[, 2], order = c(0,1,0), seasonal = c(0,1,1))
summary(arima010010)  ### 육안으로 구한 ARIMA(0,1,0)(0,1,0)[12]모델의 성능 치수 
summary(arima010011)  ### 육안으로 구한 ARIMA(0,1,0)(0,1,0)[12]모델의 성능 치수 

forecast010010 <- arima010010 %>% forecast()
forecast010011 <- arima010011 %>% forecast()

autoplot(employees.ts[, 2]) + 
  autolayer(forecast010011, PI = F, series = '010011') + 
  autolayer(forecast010010, PI = F, series = '010010')
```

위의 예제에서 육안으로 확인한 ARIMA(0,1,0)(0,1,0)[12]모델의 RMSE값은 120.50과 auto.arima()함수를 통한 ARIMA(0,1,0)(0,1,1)[12]모델의 RMSE값은 114.39이다. 일반적으로 RMSE값이 작은 모델이 성능이 좋은 모델이므로 ARIMA(0,1,0)(0,1,1)모델이 보다 우수한 것으로 볼 수 있다.

이와 같이 육안으로 확인한 ARIMA모델은 불완전하다. 따라서 육안으로 확인하거나 auto.arima 모델의 p, q값의 주위 모델을 반드시 확인하여 성능 수치가 더 우수한 모델을 찾는 과정을 거쳐야 한다.

## TBATs 모델

앞선 ETS 모델과 ARIMA 모델은 계절성을 처리할 수 있는 방법을 제공하지만 문제는 다중 계절성을 지는 경우이다. 예를 들어 시간별 데이터는 하루내에서도 계절성을 가질 수 있고 주간적으로도 계절성을 가질 수 있으며 월간적으로, 연간적으로도 계절성을 가질 수 있다. ETS 모델과 ARIMA 모델은 연간(frequency = 1), 분기간(frequency = 4), 월간(frequency = 12) 까지의 계절성을 지원하고 주간(frequency = 52) 이상의 계절성을 지원하지 못한다.

또한 계절성이 동적으로 변동되는 경우는 ETS, ARIMA 모델이 지원하지 못한다. 따라서 이렇게 긴 주기의 계절성을 찾아내는 모델이나 변동성을 지니는 계절성 데이터에 대한 모델을 구축해야 할 때 사용하는 모델이 tBats모델이다. tBats 모델은 Box-Cox 변환[^forecasting-ii-16], ARMA 에러, 추세와 계절성 컴포넌트를 사용한 지수평활 상태공간 모델이다.[^forecasting-ii-17]

[^forecasting-ii-16]: <https://otexts.com/fpp3/ftransformations.html>

[^forecasting-ii-17]: <https://pkg.robjhyndman.com/forecast/reference/tbats.html>

코로나 확진자 데이터의 경우 2020년 9월 경 한차례 증가가 있었다가 2020년 12월 또 한차례 증가가 발생했다. 이것을 이중 계절성으로 파악한다면 ETS나 ARIMA모형으로는 모델링이 불가하다. 하지만 tBats 모델은 다음과 같이 모델이 가능하다.

```{r TBATS}
wide.covid19.by.age.ts[,2] %>% tbats() %>% forecast() %>% autoplot()   ### 코로나 확진자 데이터에 대한 tBats 모델
```

## prophet 모델

## Neural Network 모델

시계열 데이터에 대한 신경망 모델은 forecast 패키지에서 제공하는 nnetar() 함수를 사용하여 구축할 수 있다. nnetar()로 구축되는 모델은 싱글 히든 레이어을 사용한 신경망 모델이다. 일반적으로 딥러닝은 히든 레이어를 3개 이상 구축한 경우를 말하기 때문에 딥러닝이라고까지는 언급할 수 없으나 시계열 데이터를 신경망 이론에 적합하여 만들수 있는 모델이라는데 의미가 있다.

nnetar() 함수에 구축된 모델은 계절성이 없는 경우는 NNAR(p, k)이며 계절성이 없는 경우는 NNAR(p, P, k)[m]으로 표현된다. p값은 히든 레이어에서 예측값을 산출하기 위해 사용하는 과거 데이터의 갯수이고 k값은 히든 레이어에 존재하는 신경세포의 갯수이다. P는 계절성에 대한 lag 값이다. nnetar() 함수는 p와 P 값을 자동으로 산정하고 k 값은 (p + P +1)/2 값으로 설정한다.[^forecasting-ii-18]

[^forecasting-ii-18]: <https://otexts.com/fpp3/nnetar.html>

NNAR모델의 단점중에 하나는 예측구간의 계산이 원활하지 못하다는 점이다. forecast() 함수에서 'PI = TRUE' 매개변수를 설정하면 예측구간이 계산되지만 계산량이 많아 시간이 걸린다.

```{r nnetar}
### 학생수에 대한 NNAR 모델은 NNAR(1, 1)모델
students.total.ts[,1] %>% nnetar() %>% forecast(PI = TRUE) %>% autoplot()
### 전체 취업자수에 대한 모델은 NNAR(1, 1, 2)[12] 모델
employees.ts[, 2] %>% nnetar() %>% forecast(PI = TRUE) %>% autoplot()
### 코로나 확진자수에 대한 모델은 NNAR(22, 12) 모델(예측값을 위해 22개의 과거 데이터를 활용했고 히든레이어에 12개의 신경세포를 생성 )
wide.covid19.by.age.ts[,2] %>% nnetar() %>% forecast(h = 100, PI = TRUE) %>% autoplot()
```
